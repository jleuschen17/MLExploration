{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#https://github.com/jleuschen17/EE399/tree/master/homework5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy import integrate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = [12, 12]\n",
    "\n",
    "dt = 0.01\n",
    "T = 8\n",
    "t = np.arange(0, T + dt, dt)\n",
    "beta = 8 / 3\n",
    "sigma = 10\n",
    "rho = 28\n",
    "\n",
    "nn_input = np.zeros((100 * (len(t) - 1), 3))\n",
    "nn_output = np.zeros_like(nn_input)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, subplot_kw={'projection': '3d'})\n",
    "\n",
    "\n",
    "def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "    x, y, z = x_y_z\n",
    "    return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "x0 = -15 + 30 * np.random.random((100, 3))\n",
    "\n",
    "x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t)\n",
    "                  for x0_j in x0])\n",
    "\n",
    "for j in range(100):\n",
    "    nn_input[j * (len(t) - 1):(j + 1) * (len(t) - 1), :] = x_t[j, :-1, :]\n",
    "    nn_output[j * (len(t) - 1):(j + 1) * (len(t) - 1), :] = x_t[j, 1:, :]\n",
    "    x, y, z = x_t[j, :, :].T\n",
    "    ax.plot(x, y, z, linewidth=1)\n",
    "    ax.scatter(x0[j, 0], x0[j, 1], x0[j, 2], color='r')\n",
    "\n",
    "ax.view_init(18, -113)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "Score for (17, 10): 0.030179197637968776\n",
      "Score for (17, 28): 0.08080873749633419\n",
      "Score for (17, 40): 0.37662657252229165\n",
      "Score for (35, 10): 0.4269531807052016\n",
      "Score for (35, 28): 0.08866815628599797\n",
      "Score for (35, 40): 0.06534498832107813\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.9904\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0055\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 0.0046\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0039\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0038\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0032\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0027\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0023\n",
      "Epoch 9/10\n",
      " 721/1250 [================>.............] - ETA: 1s - loss: 0.0019"
     ]
    }
   ],
   "source": [
    "\n",
    "models = {}\n",
    "rhos = [10, 28, 40]\n",
    "for rho in rhos:\n",
    "    models[rho] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation='relu', input_shape=(3,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "\n",
    "for rho in rhos:\n",
    "    models[rho].compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "\n",
    "for rho in rhos:\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t) for x0_j in x0])\n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "\n",
    "    models[rho].fit(nn_input, nn_output, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "\n",
    "test_rhos = [17, 35]\n",
    "results = {}\n",
    "\n",
    "for rho in test_rhos:\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    for rho2 in rhos:\n",
    "        x_test = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t) for x0_j in x0])\n",
    "\n",
    "\n",
    "        test_input = x_test[:, :-1, :].reshape(-1, 3)\n",
    "\n",
    "        predictions = models[rho2].predict(test_input)\n",
    "\n",
    "        predictions = predictions.reshape(x_test.shape[0], -1, 3)\n",
    "\n",
    "        mse = np.mean((predictions - x_test[:, 1:, :]) ** 2)\n",
    "\n",
    "        results[(rho, rho2)] = mse\n",
    "\n",
    "for (i, j) in results:\n",
    "    print(f\"Score for {i, j}: {results[(i, j)]}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model for rho: 10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 2.4954\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0061\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0022\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0013\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 8.7367e-04\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 8.3471e-04\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 6.5989e-04\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 6.1723e-04\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 5.6148e-04\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 5.4006e-04\n",
      "Training RNN model for rho: 10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 1.6802\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0072\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0051\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0044\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0036\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0032\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0029\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0026\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0024\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0022\n",
      "Training ESN model for rho: 10\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.4472\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.4477\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.2074\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1016\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0623\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0459\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0370\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0316\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0281\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.0257\n",
      "Training LSTM model for rho: 28\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 5s 3ms/step - loss: 13.8716\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0257\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0076\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0047\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0038\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0035\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0028\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0027\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0024\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0023\n",
      "Training RNN model for rho: 28\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 3.8606\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0642\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0409\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0288\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0237\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0219\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0185\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0161\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0141\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0128\n",
      "Training ESN model for rho: 28\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 44.7879\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.4991\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.7133\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.4655\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.3122\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.2307\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1909\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1693\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1544\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.1439\n",
      "Training LSTM model for rho: 40\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 28.0361\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0377\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0146\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0084\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0064\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0057\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 4s 3ms/step - loss: 0.0048\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0041\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 3s 3ms/step - loss: 0.0049\n",
      "Training RNN model for rho: 40\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 3s 2ms/step - loss: 13.7434\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.1807\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.1180\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0841\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0679\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0569\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0510\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0461\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0412\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 2ms/step - loss: 0.0368\n",
      "Training ESN model for rho: 40\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 156.6242\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 6.6653\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 2.6718\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 1.2531\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.8064\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.6074\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.4953\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.4261\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.3832\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 2s 1ms/step - loss: 0.3580\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 2s 623us/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 2s 631us/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 2s 627us/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 2s 613us/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 2s 619us/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "2500/2500 [==============================] - 2s 619us/step\n",
      "2500/2500 [==============================] - 3s 1ms/step\n",
      "Results for LSTM models:\n",
      "Score for (17, 10): 0.07343708620652381\n",
      "Score for (17, 28): 0.2014409418392321\n",
      "Score for (17, 40): 0.8126058398387972\n",
      "Score for (35, 10): 2.1803333411452535\n",
      "Score for (35, 28): 0.1258781571419851\n",
      "Score for (35, 40): 0.09148553966617765\n",
      "Results for RNN models:\n",
      "Score for (17, 10): 0.044426653285796563\n",
      "Score for (17, 28): 0.09530823702967053\n",
      "Score for (17, 40): 0.3786809835349209\n",
      "Score for (35, 10): 0.5354498724523316\n",
      "Score for (35, 28): 0.06904623786137835\n",
      "Score for (35, 40): 0.04847393575326232\n",
      "Results for ESN models:\n",
      "Score for (17, 10): 0.10037576003092682\n",
      "Score for (17, 28): 0.13050034450714593\n",
      "Score for (17, 40): 0.20617033112240676\n",
      "Score for (35, 10): 0.8093418592208039\n",
      "Score for (35, 28): 0.2644770442505937\n",
      "Score for (35, 40): 0.2571220644409199\n"
     ]
    }
   ],
   "source": [
    "\n",
    "esn_models = {}\n",
    "lstm_models = {}\n",
    "rnn_models = {}\n",
    "\n",
    "for rho in rhos:\n",
    "    lstm_models[rho] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(32, activation='relu', input_shape=(1, 3), return_sequences=True),\n",
    "        tf.keras.layers.LSTM(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "\n",
    "    rnn_models[rho] = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.SimpleRNN(32, activation='relu', input_shape=(1, 3), return_sequences=True),\n",
    "        tf.keras.layers.SimpleRNN(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    esn_models[rho] = tf.keras.models.Sequential([\n",
    "        tfa.layers.ESN(32, activation='relu', input_shape=(1, 3), return_sequences=True),\n",
    "        tfa.layers.ESN(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "\n",
    "for rho in rhos:\n",
    "    lstm_models[rho].compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "    rnn_models[rho].compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "    esn_models[rho].compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mse')\n",
    "\n",
    "for rho in rhos:\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    x_t = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t) for x0_j in x0])\n",
    "    for j in range(100):\n",
    "        nn_input[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,:-1,:]\n",
    "        nn_output[j*(len(t)-1):(j+1)*(len(t)-1),:] = x_t[j,1:,:]\n",
    "\n",
    "    print(f\"Training LSTM model for rho: {rho}\")\n",
    "    lstm_models[rho].fit(np.expand_dims(nn_input, axis=1), nn_output, epochs=10, batch_size=64, verbose=1)\n",
    "    print(f\"Training RNN model for rho: {rho}\")\n",
    "    rnn_models[rho].fit(np.expand_dims(nn_input, axis=1), nn_output, epochs=10, batch_size=64, verbose=1)\n",
    "    print(f\"Training ESN model for rho: {rho}\")\n",
    "    esn_models[rho].fit(np.expand_dims(nn_input, axis=1), nn_output, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "\n",
    "test_lstm_results = {}\n",
    "test_rnn_results = {}\n",
    "test_esn_results = {}\n",
    "\n",
    "for rho in test_rhos:\n",
    "\n",
    "    def lorenz_deriv(x_y_z, t0, sigma=sigma, beta=beta, rho=rho):\n",
    "        x, y, z = x_y_z\n",
    "        return [sigma * (y - x), x * (rho - z) - y, x * y - beta * z]\n",
    "\n",
    "    for rho2 in rhos:\n",
    "        x_test = np.asarray([integrate.odeint(lorenz_deriv, x0_j, t) for x0_j in x0])\n",
    "\n",
    "        test_input = x_test[:, :-1, :].reshape(-1, 3)\n",
    "\n",
    "        lstm_predictions = lstm_models[rho2].predict(np.expand_dims(test_input, axis=1))\n",
    "        rnn_predictions = rnn_models[rho2].predict(np.expand_dims(test_input, axis=1))\n",
    "        esn_predictions = esn_models[rho2].predict(np.expand_dims(test_input, axis=1))\n",
    "\n",
    "        lstm_predictions = lstm_predictions.reshape(x_test.shape[0], -1, 3)\n",
    "        rnn_predictions = rnn_predictions.reshape(x_test.shape[0], -1, 3)\n",
    "        esn_predictions = esn_predictions.reshape(x_test.shape[0], -1, 3)\n",
    "\n",
    "\n",
    "        lstm_mse = np.mean((lstm_predictions - x_test[:, 1:, :])**2)\n",
    "        rnn_mse = np.mean((rnn_predictions - x_test[:, 1:, :])**2)\n",
    "        esn_mse = np.mean((esn_predictions - x_test[:, 1:, :])**2)\n",
    "\n",
    "        test_lstm_results[(rho, rho2)] = lstm_mse\n",
    "        test_rnn_results[(rho, rho2)] = rnn_mse\n",
    "        test_esn_results[(rho, rho2)] = esn_mse\n",
    "\n",
    "\n",
    "\n",
    "print(\"Results for LSTM models:\")\n",
    "for (i, j) in test_lstm_results:\n",
    "    print(f\"Score for {i, j}: {test_lstm_results[(i, j)]}\")\n",
    "\n",
    "print(\"Results for RNN models:\")\n",
    "for (i, j) in test_rnn_results:\n",
    "    print(f\"Score for {i, j}: {test_rnn_results[(i, j)]}\")\n",
    "\n",
    "print(\"Results for ESN models:\")\n",
    "for (i, j) in test_esn_results:\n",
    "    print(f\"Score for {i, j}: {test_esn_results[(i, j)]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Score for (17, 10): 0.0472684074568874\n",
    "Score for (17, 28): 0.09034684125173521\n",
    "Score for (17, 40): 0.3974588104508566\n",
    "Score for (35, 10): 0.5181165348005903\n",
    "Score for (35, 28): 0.06629825489183239\n",
    "Score for (35, 40): 0.07582859700073742"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}